/**
 * Cron Job: å®šæ—¶çˆ¬å–ç§‘å­¦æ–‡ç« 
 * 
 * é…ç½®åœ¨ vercel.json ä¸­ï¼š
 * - æ¯å¤©æ—©ä¸Š 6:00 UTC (åŒ—äº¬æ—¶é—´ 14:00) æ‰§è¡Œ
 * 
 * æ‰‹åŠ¨è§¦å‘ï¼š
 * curl -X GET "https://your-domain/api/cron/crawl-content" \
 *   -H "Authorization: Bearer YOUR_CRON_SECRET"
 */

import { NextRequest, NextResponse } from 'next/server';
import { quickCrawl, crawlAndStoreArticles } from '@/lib/content-crawler';

export const runtime = 'nodejs';
export const maxDuration = 300; // 5 åˆ†é’Ÿè¶…æ—¶

/**
 * éªŒè¯ Cron è¯·æ±‚
 * Vercel Cron ä¼šè‡ªåŠ¨æ·»åŠ  Authorization header
 */
function verifyCronRequest(request: NextRequest): boolean {
  // Vercel Cron è‡ªåŠ¨éªŒè¯
  const authHeader = request.headers.get('authorization');
  if (authHeader === `Bearer ${process.env.CRON_SECRET}`) {
    return true;
  }
  
  // æ£€æŸ¥ Vercel çš„ cron ç­¾å
  const vercelCron = request.headers.get('x-vercel-cron');
  if (vercelCron) {
    return true;
  }
  
  return false;
}

export async function GET(request: NextRequest) {
  // éªŒè¯è¯·æ±‚æ¥æº
  if (!verifyCronRequest(request)) {
    console.warn('ğŸš« Unauthorized cron request');
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  console.log('â° Cron job started: crawl-content');
  const startTime = Date.now();

  try {
    // å·¥ä½œæ—¥ç”¨ quick æ¨¡å¼ï¼Œå‘¨æœ«ç”¨ full æ¨¡å¼
    const today = new Date();
    const isWeekend = today.getDay() === 0 || today.getDay() === 6;
    
    let result;
    if (isWeekend) {
      // å‘¨æœ«ï¼šå®Œæ•´çˆ¬å–ï¼ˆæ›´å¤šæ–‡ç« ï¼‰
      console.log('ğŸ“š Weekend mode: full crawl');
      result = await crawlAndStoreArticles(15);
      
      return NextResponse.json({
        success: result.success,
        mode: 'full',
        message: `å‘¨æœ«å®Œæ•´çˆ¬å–ï¼šPubMed ${result.pubmedCount} ç¯‡ï¼ŒSemantic Scholar ${result.semanticCount} ç¯‡ï¼ŒReddit ${result.redditCount} æ¡ï¼ŒX ${result.xCount} æ¡`,
        pubmedCount: result.pubmedCount,
        semanticCount: result.semanticCount,
        redditCount: result.redditCount,
        xCount: result.xCount,
        duration: `${((Date.now() - startTime) / 1000).toFixed(1)}s`,
        errors: result.errors.length,
      });
    } else {
      // å·¥ä½œæ—¥ï¼šå¿«é€Ÿçˆ¬å–
      console.log('âš¡ Weekday mode: quick crawl');
      result = await quickCrawl();
      
      return NextResponse.json({
        success: result.success,
        mode: 'quick',
        message: `å·¥ä½œæ—¥å¿«é€Ÿçˆ¬å–ï¼š${result.count} æ¡å†…å®¹ï¼ˆReddit ${result.redditCount}ï¼ŒX ${result.xCount}ï¼‰`,
        count: result.count,
        redditCount: result.redditCount,
        xCount: result.xCount,
        duration: `${((Date.now() - startTime) / 1000).toFixed(1)}s`,
        errors: result.errors.length,
      });
    }
  } catch (error) {
    console.error('âŒ Cron crawl error:', error);
    return NextResponse.json(
      { 
        error: 'Crawl failed',
        message: error instanceof Error ? error.message : 'Unknown error',
        duration: `${((Date.now() - startTime) / 1000).toFixed(1)}s`,
      },
      { status: 500 }
    );
  }
}
